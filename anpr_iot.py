# -*- coding: utf-8 -*-
"""ANPR_IOT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XgkCqhPIOaWct4Q0iC-mNuSeQloYbffg
"""

!pip install ultralytics opencv-python pytesseract
!pip install paddlepaddle paddleocr

import cv2
import numpy as np
import time
from ultralytics import YOLO
from paddleocr import PaddleOCR
from PIL import Image
import re
from google.colab.patches import cv2_imshow  # Para mostrar imágenes en Colab
from IPython.display import display
import matplotlib.pyplot as plt

# Cargar modelo YOLOv11 y OCR
model = YOLO("best.pt")  # Reemplaza con tu modelo YOLOv11 entrenado para matrículas
ocr = PaddleOCR(use_angle_cls=True, lang="en")

def extract_license_plate(ocr_result, confidence_threshold=0.7):
    """
    Extrae y limpia el texto OCR con mayor confianza.
    """
    if not ocr_result or not ocr_result[0]:
        return "No plate detected", 0.0

    best_text = ""
    max_confidence = 0

    for detection in ocr_result[0]:
        text = detection[1][0]
        confidence = detection[1][1]

        if confidence > confidence_threshold and confidence > max_confidence:
            best_text = text
            max_confidence = confidence

    cleaned_text = re.sub(r'[^A-Za-z0-9]', '', best_text).upper()
    return cleaned_text if cleaned_text else "No plate detected", max_confidence

def detect_and_recognize(image):
    """
    Detecta y reconoce matrículas desde una imagen con YOLOv11 y PaddleOCR.
    """
    image = np.array(image)
    original_image = image.copy()
    detected_text = "No plate detected"
    confidence_score = 0.0

    # Detección con YOLO
    results = model.predict(source=image, save=False)
    detections = results[0].boxes.data

    if len(detections) == 0:
        print("No se detectaron matrículas.")
        return original_image, detected_text, confidence_score

    for detection in detections[:1]:  # Solo la primera detección
        x1, y1, x2, y2, conf, cls = detection[:6]
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])

        plate_image = image[y1:y2, x1:x2]

        # OCR
        ocr_result = ocr.ocr(plate_image, cls=True)
        detected_text, confidence_score = extract_license_plate(ocr_result)

        if detected_text != "No plate detected":
            cv2.rectangle(original_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(original_image, detected_text, (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    return original_image, detected_text, confidence_score

from google.colab import files
uploaded = files.upload()

# Cargar imagen subida
from PIL import Image
image_path = list(uploaded.keys())[0]
image = Image.open(image_path).convert("RGB")
image

processed_image, plate_text, score = detect_and_recognize(image)
print(f"Matrícula detectada: {plate_text} (Confianza: {score:.2f})")
cv2_imshow(processed_image)